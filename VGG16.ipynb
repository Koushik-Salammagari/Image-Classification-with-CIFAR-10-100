{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QfGazhCWHDin"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "h83ZsSFjHtXY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "i3k3o-9gHtdA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
      ],
      "metadata": {
        "id": "5eUX1YSsHtkK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "xDxIN5PAIZKk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    vgg16,\n",
        "    Flatten(),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "6T9ZaRhFJAtR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import dropout\n",
        "learning_rates = [0.001, 0.0001, 0.1]\n",
        "batch_sizes = [32, 64, 128]\n",
        "num_epochs = 7\n",
        "#dropout= [0.3]\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "          model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "          model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n",
        "          # Evaluate the model on the test data\n",
        "          y_pred = model.predict(x_test)\n",
        "          y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "          accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "          print(f'Learning rate: {lr}, Batch size: {batch_size} Accuracy: {accuracy}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g135tMeYJAvl",
        "outputId": "60581b4f-29cf-410f-afef-50a74836765c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 1.4159 - accuracy: 0.5065 - val_loss: 1.3039 - val_accuracy: 0.5503\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.2139 - accuracy: 0.5783 - val_loss: 1.2065 - val_accuracy: 0.5766\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.1276 - accuracy: 0.6053 - val_loss: 1.2088 - val_accuracy: 0.5842\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.0664 - accuracy: 0.6291 - val_loss: 1.1607 - val_accuracy: 0.5994\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.0138 - accuracy: 0.6445 - val_loss: 1.1603 - val_accuracy: 0.6052\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.9673 - accuracy: 0.6607 - val_loss: 1.1452 - val_accuracy: 0.6133\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.9206 - accuracy: 0.6731 - val_loss: 1.1339 - val_accuracy: 0.6151\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Learning rate: 0.001, Batch size: 32 Accuracy: 0.6151\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 20s 23ms/step - loss: 0.8221 - accuracy: 0.7043 - val_loss: 1.2128 - val_accuracy: 0.6235\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.7696 - accuracy: 0.7239 - val_loss: 1.2190 - val_accuracy: 0.6270\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.7211 - accuracy: 0.7391 - val_loss: 1.2585 - val_accuracy: 0.6193\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.6823 - accuracy: 0.7528 - val_loss: 1.2674 - val_accuracy: 0.6233\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.6336 - accuracy: 0.7661 - val_loss: 1.3986 - val_accuracy: 0.6100\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.5897 - accuracy: 0.7822 - val_loss: 1.3974 - val_accuracy: 0.6188\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5582 - accuracy: 0.7966 - val_loss: 1.4534 - val_accuracy: 0.6108\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Learning rate: 0.001, Batch size: 64 Accuracy: 0.6108\n",
            "Epoch 1/7\n",
            "391/391 [==============================] - 18s 38ms/step - loss: 0.4443 - accuracy: 0.8361 - val_loss: 1.7030 - val_accuracy: 0.6126\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3882 - accuracy: 0.8562 - val_loss: 1.8165 - val_accuracy: 0.6105\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.3427 - accuracy: 0.8739 - val_loss: 1.9652 - val_accuracy: 0.6180\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.3046 - accuracy: 0.8887 - val_loss: 2.1193 - val_accuracy: 0.6158\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2934 - accuracy: 0.8925 - val_loss: 2.0304 - val_accuracy: 0.6149\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.2513 - accuracy: 0.9087 - val_loss: 2.2453 - val_accuracy: 0.6135\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.2366 - accuracy: 0.9146 - val_loss: 2.2927 - val_accuracy: 0.6113\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Learning rate: 0.001, Batch size: 128 Accuracy: 0.6113\n",
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 29s 17ms/step - loss: 0.1242 - accuracy: 0.9575 - val_loss: 2.6622 - val_accuracy: 0.6221\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0877 - accuracy: 0.9719 - val_loss: 2.9004 - val_accuracy: 0.6228\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0751 - accuracy: 0.9762 - val_loss: 3.1165 - val_accuracy: 0.6241\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 3.2581 - val_accuracy: 0.6202\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 3.4238 - val_accuracy: 0.6226\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 3.5399 - val_accuracy: 0.6211\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0443 - accuracy: 0.9874 - val_loss: 3.7137 - val_accuracy: 0.6217\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Learning rate: 0.0001, Batch size: 32 Accuracy: 0.6217\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 20s 23ms/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 3.9511 - val_accuracy: 0.6226\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 4.0483 - val_accuracy: 0.6236\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 3.9517 - val_accuracy: 0.6250\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 4.1759 - val_accuracy: 0.6236\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 4.1480 - val_accuracy: 0.6218\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 4.1519 - val_accuracy: 0.6199\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.0258 - accuracy: 0.9939 - val_loss: 4.1828 - val_accuracy: 0.6213\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Learning rate: 0.0001, Batch size: 64 Accuracy: 0.6213\n",
            "Epoch 1/7\n",
            "391/391 [==============================] - 15s 35ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 4.3343 - val_accuracy: 0.6224\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 4.5023 - val_accuracy: 0.6222\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 4.4511 - val_accuracy: 0.6243\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 4.4842 - val_accuracy: 0.6245\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 4.5316 - val_accuracy: 0.6201\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 4.5881 - val_accuracy: 0.6210\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 4.5333 - val_accuracy: 0.6241\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Learning rate: 0.0001, Batch size: 128 Accuracy: 0.6241\n",
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 29s 18ms/step - loss: 27.2189 - accuracy: 0.1012 - val_loss: 2.3194 - val_accuracy: 0.1000\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 2.3587 - accuracy: 0.1023 - val_loss: 2.3111 - val_accuracy: 0.1000\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 5.5930 - accuracy: 0.1027 - val_loss: 2.3275 - val_accuracy: 0.1000\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 2.3147 - accuracy: 0.0981 - val_loss: 2.3113 - val_accuracy: 0.1000\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 2.3163 - accuracy: 0.0991 - val_loss: 2.3183 - val_accuracy: 0.1000\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 2.3148 - accuracy: 0.1006 - val_loss: 2.3073 - val_accuracy: 0.1000\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 2.3151 - accuracy: 0.0998 - val_loss: 2.3165 - val_accuracy: 0.1000\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Learning rate: 0.1, Batch size: 32 Accuracy: 0.1\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 20s 24ms/step - loss: 2.3113 - accuracy: 0.0991 - val_loss: 2.3147 - val_accuracy: 0.1000\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.3111 - accuracy: 0.1002 - val_loss: 2.3086 - val_accuracy: 0.1000\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.3121 - accuracy: 0.0999 - val_loss: 2.3203 - val_accuracy: 0.1000\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 2.3128 - accuracy: 0.1009 - val_loss: 2.3126 - val_accuracy: 0.1000\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 18s 22ms/step - loss: 2.3109 - accuracy: 0.0986 - val_loss: 2.3115 - val_accuracy: 0.1000\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.3111 - accuracy: 0.1003 - val_loss: 2.3090 - val_accuracy: 0.1000\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.3110 - accuracy: 0.1006 - val_loss: 2.3206 - val_accuracy: 0.1000\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Learning rate: 0.1, Batch size: 64 Accuracy: 0.1\n",
            "Epoch 1/7\n",
            "391/391 [==============================] - 16s 35ms/step - loss: 2.3091 - accuracy: 0.0984 - val_loss: 2.3092 - val_accuracy: 0.1000\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 2.3089 - accuracy: 0.0988 - val_loss: 2.3084 - val_accuracy: 0.1000\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 2.3093 - accuracy: 0.0987 - val_loss: 2.3095 - val_accuracy: 0.1000\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 2.3084 - accuracy: 0.1012 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 13s 32ms/step - loss: 2.3092 - accuracy: 0.0968 - val_loss: 2.3063 - val_accuracy: 0.1000\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 2.3086 - accuracy: 0.1008 - val_loss: 2.3123 - val_accuracy: 0.1000\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 2.3087 - accuracy: 0.1014 - val_loss: 2.3119 - val_accuracy: 0.1000\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Learning rate: 0.1, Batch size: 128 Accuracy: 0.1\n"
          ]
        }
      ]
    }
  ]
}